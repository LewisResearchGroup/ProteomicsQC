{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Django3 Omics Pipelines A web-server to setup processing pipelines proteomics .RAW files. 1) Create a project 2) Create a pipeline by providing a fasta file and a MaxQuant parameter template (mqpar.xml) 3) Submit .RAW files to the pipeline 4) Download results 5) Explore data with the integrated dashboard The server organizes files into projects. Therefore, at least one project hast to be created. Then a pipeline can be created. Herefore, a MaxQuant parameter file (mqpar.xml) and a fasta file have to be provided. MaxQuant Parameter file ( mqpar.xml ) The mqpar.xml has to be created as a blueprint for the pipeline jobs for example using the MaxQuant GUI. The pipeline is currently restricted to process a single .RAW per job, therefore the mqpar.xml file has to be created with a single .RAW file . The MaxQuant version supported is MaxQuant 1.6.10 due to limited compatability between .NET versions used by MaxQuant and current mono versions. mono is a reimplementation for .NET that runs on Linux platforms.ll","title":"Home"},{"location":"#django3-omics-pipelines","text":"A web-server to setup processing pipelines proteomics .RAW files. 1) Create a project 2) Create a pipeline by providing a fasta file and a MaxQuant parameter template (mqpar.xml) 3) Submit .RAW files to the pipeline 4) Download results 5) Explore data with the integrated dashboard The server organizes files into projects. Therefore, at least one project hast to be created. Then a pipeline can be created. Herefore, a MaxQuant parameter file (mqpar.xml) and a fasta file have to be provided.","title":"Django3 Omics Pipelines"},{"location":"#maxquant-parameter-file-mqparxml","text":"The mqpar.xml has to be created as a blueprint for the pipeline jobs for example using the MaxQuant GUI. The pipeline is currently restricted to process a single .RAW per job, therefore the mqpar.xml file has to be created with a single .RAW file . The MaxQuant version supported is MaxQuant 1.6.10 due to limited compatability between .NET versions used by MaxQuant and current mono versions. mono is a reimplementation for .NET that runs on Linux platforms.ll","title":"MaxQuant Parameter file (mqpar.xml)"},{"location":"#_1","text":"","title":""},{"location":"about/","text":"About The LRG Proteomics Pipelines server is maintained by Lewis Research Group at the University of Calgary, Canada. The software can be used free of charge and comes without any warranties for the correctness of the generated results.","title":"About"},{"location":"about/#about","text":"The LRG Proteomics Pipelines server is maintained by Lewis Research Group at the University of Calgary, Canada. The software can be used free of charge and comes without any warranties for the correctness of the generated results.","title":"About"},{"location":"api/","text":"Submit a raw file via the API Raw files can be submitted to an existing pipeline using the API. To submit a raw file the UUID of the user and the target pipeline are required which can be found in the admin panel. The target URL is: https://proteomics.resistancedb.org/upload/raw The curl command looks like: URL=https://proteomics.resistancedb.org/upload/ curl -v -i -F orig_file=\"@</your/file.raw>\" -F pipeline=3388219a-f9cd-4749-9f5e-d9da5bca9286 -F user=gd5d56ac-1rb9-4181-8fbd-b6579ccb8fc1 $URL Alternatively, the python script lrg_upload_raw_file_to_qc_pipeline.py that is part of the lrg_omics packages can be used: python lrg_upload_raw_file_to_qc_pipeline.py --raw your/file.raw --host https://example.com --user 3388219a-f9cd-4749-9f5e-d9da5bca9286 --pipeline gd5d56ac-1rb9-4181-8fbd-b6579ccb8fc1","title":"API"},{"location":"api/#submit-a-raw-file-via-the-api","text":"Raw files can be submitted to an existing pipeline using the API. To submit a raw file the UUID of the user and the target pipeline are required which can be found in the admin panel. The target URL is: https://proteomics.resistancedb.org/upload/raw The curl command looks like: URL=https://proteomics.resistancedb.org/upload/ curl -v -i -F orig_file=\"@</your/file.raw>\" -F pipeline=3388219a-f9cd-4749-9f5e-d9da5bca9286 -F user=gd5d56ac-1rb9-4181-8fbd-b6579ccb8fc1 $URL Alternatively, the python script lrg_upload_raw_file_to_qc_pipeline.py that is part of the lrg_omics packages can be used: python lrg_upload_raw_file_to_qc_pipeline.py --raw your/file.raw --host https://example.com --user 3388219a-f9cd-4749-9f5e-d9da5bca9286 --pipeline gd5d56ac-1rb9-4181-8fbd-b6579ccb8fc1","title":"Submit a raw file via the API"},{"location":"datalake/","text":"The datalake The datalake is the central data storage of the proteomics pipelines framework. Its location is shared with the web-site and celery workers. The location of the data lake on the host system can be controled with the DATALAKE=/var/www/html/omics/datalake variable in the .env file. /var/www/html/omics/datalake/ \u251c\u2500\u2500 P \u2502 \u2514\u2500\u2500 P1 \u2502 \u2514\u2500\u2500 P1MQ1 \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u251c\u2500\u2500 fasta.faa \u2502 \u2502 \u2514\u2500\u2500 mqpar.xml \u2502 \u251c\u2500\u2500 inputs \u2502 \u2502 \u251c\u2500\u2500 fake3 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-A-200507.raw \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-B-200507 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-B-200507.raw ... The proteomics jobs read the input files from the datalake from the config and input folders of the current project and write the MaxQuant and RawTools output to the corresponding output directory. The output directory is organized by file , so that all data from one file is collected in one subfolder. ... \u2502 \u251c\u2500\u2500 output \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw \u2502 \u2502 \u2502 \u251c\u2500\u2500 maxquant \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 allPeptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 evidence.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 libraryMatch.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 matchedFeatures.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 maxquant_quality_control.csv \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 modificationSpecificPeptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ms3Scans.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 msmsScans.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 msms.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mzRange.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 Oxidation (M)Sites.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 parameters.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 peptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 proteinGroups.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 summary.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 tables.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_log.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_metrics.err \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_metrics.out \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Matrix.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Metrics.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw.mgf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms2_BP_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms2_TIC_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms_BP_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-A-200507.raw_Ms_TIC_chromatogram.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 rawtools_qc \u2502 \u2502 \u2502 \u251c\u2500\u2500 QcDataTable.csv \u2502 \u2502 \u2502 \u251c\u2500\u2500 QC.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_log.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_qc.err \u2502 \u2502 \u2502 \u2514\u2500\u2500 rawtools_qc.out ... Certain fractions of the data are cleaned and stored in a columnar data format ( parquet ) to enable fast reads. This data is a simplified and standardized version of the data in the output folder and can be regenerated easily and is organized by data type rather than by input file, in contrast to the output directory. \u2502 \u251c\u2500\u2500 parquet \u2502 \u2502 \u2514\u2500\u2500 protein_groups \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-B-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-blank-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-C-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-D-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-E-200507.parquet ...","title":"Datalake"},{"location":"datalake/#the-datalake","text":"The datalake is the central data storage of the proteomics pipelines framework. Its location is shared with the web-site and celery workers. The location of the data lake on the host system can be controled with the DATALAKE=/var/www/html/omics/datalake variable in the .env file. /var/www/html/omics/datalake/ \u251c\u2500\u2500 P \u2502 \u2514\u2500\u2500 P1 \u2502 \u2514\u2500\u2500 P1MQ1 \u2502 \u251c\u2500\u2500 config \u2502 \u2502 \u251c\u2500\u2500 fasta.faa \u2502 \u2502 \u2514\u2500\u2500 mqpar.xml \u2502 \u251c\u2500\u2500 inputs \u2502 \u2502 \u251c\u2500\u2500 fake3 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-A-200507.raw \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-B-200507 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-B-200507.raw ... The proteomics jobs read the input files from the datalake from the config and input folders of the current project and write the MaxQuant and RawTools output to the corresponding output directory. The output directory is organized by file , so that all data from one file is collected in one subfolder. ... \u2502 \u251c\u2500\u2500 output \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw \u2502 \u2502 \u2502 \u251c\u2500\u2500 maxquant \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 allPeptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 evidence.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 libraryMatch.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 matchedFeatures.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 maxquant_quality_control.csv \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 modificationSpecificPeptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 ms3Scans.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 msmsScans.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 msms.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 mzRange.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 Oxidation (M)Sites.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 parameters.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 peptides.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 proteinGroups.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 summary.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 tables.pdf \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_log.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_metrics.err \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_metrics.out \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Matrix.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Metrics.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw.mgf \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms2_BP_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms2_TIC_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.raw_Ms_BP_chromatogram.txt \u2502 \u2502 \u2502 \u2502 \u2514\u2500\u2500 SA001-R1-A-200507.raw_Ms_TIC_chromatogram.txt \u2502 \u2502 \u2502 \u2514\u2500\u2500 rawtools_qc \u2502 \u2502 \u2502 \u251c\u2500\u2500 QcDataTable.csv \u2502 \u2502 \u2502 \u251c\u2500\u2500 QC.xml \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_log.txt \u2502 \u2502 \u2502 \u251c\u2500\u2500 rawtools_qc.err \u2502 \u2502 \u2502 \u2514\u2500\u2500 rawtools_qc.out ... Certain fractions of the data are cleaned and stored in a columnar data format ( parquet ) to enable fast reads. This data is a simplified and standardized version of the data in the output folder and can be regenerated easily and is organized by data type rather than by input file, in contrast to the output directory. \u2502 \u251c\u2500\u2500 parquet \u2502 \u2502 \u2514\u2500\u2500 protein_groups \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-A-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-B-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-blank-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-C-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-D-200507.parquet \u2502 \u2502 \u251c\u2500\u2500 SA001-R1-E-200507.parquet ...","title":"The datalake"},{"location":"installation/","text":"Installation 1) Docker-compose The server can be started with docker-compose . Therefore, docker and docker-compose have to be installed on the host. The server can also be used without docker-compose, if the postgres and redis servers are running already. For official Docker installation instructions please visit: https://docs.docker.com/engine/install/ubuntu/ 2) Download the repository git clone --recursive git@github.com:soerendip/django3-omics-pipelines.git 3) Create configuration file ./scripts/generate_config.sh # generates a .env file for configuration 4) Initiate database make init # to start the server the first time 5) make run # starts the production server on port 8000","title":"Installation"},{"location":"installation/#installation","text":"","title":"Installation"},{"location":"installation/#1-docker-compose","text":"The server can be started with docker-compose . Therefore, docker and docker-compose have to be installed on the host. The server can also be used without docker-compose, if the postgres and redis servers are running already. For official Docker installation instructions please visit: https://docs.docker.com/engine/install/ubuntu/","title":"1) Docker-compose"},{"location":"installation/#2-download-the-repository","text":"git clone --recursive git@github.com:soerendip/django3-omics-pipelines.git","title":"2) Download the repository"},{"location":"installation/#3-create-configuration-file","text":"./scripts/generate_config.sh # generates a .env file for configuration","title":"3) Create configuration file"},{"location":"installation/#4-initiate-database","text":"make init # to start the server the first time","title":"4) Initiate database"},{"location":"installation/#5","text":"make run # starts the production server on port 8000","title":"5)"},{"location":"make/","text":"The docker-compose setup spins up two docker containers. One for the web-page and one for the the postgres database. make build to build the containers make migrations to create database migrations make migrate to migrate the database make createsuperuser to create credentials for a superuser make run to run the website and postgres database. make init initiate the database","title":"Make"},{"location":"manual/","text":"User manual Please, have a look at the installation instructions and how to start the pipeline server. Login with an admin account When you visit the website for the first time you will be redirected to the login page. A new user can register a new account with a valid email address. To visit the admin page the user has to be granted the rights by an admin. If you do not have setup an admin account To setup a Setup MaxQuant To setup MaxQuant you can upload a zipped MaxQuant version. Version 1.6.14 works with Mono and is the recommended version to use with the Proteomics Pipelines server. Please contact the MaxQuant mailing list for information on how to obtain older versions. Once you downloaded the zip-file you can upload it to the Pipeline server. Go to 'admin/pipelines/maxquantbin/add' and upload the zip file from Admin / Max quant bins / ADD MAX QUANT BIN . If successful the executable will be selectable under Admin / Max quant setups / ADD MAX QUANT SETUP/ . If this is done you can create your first pipeline. Create first pipeline 1. Create a new project At least one project has to be set up. Navigate to Admin / Projects / ADD PROJECT and provide a name and a description. 2. Upload Fasta File A fasta file with protein sequences has to be uploaded. 3. Upload mqpar.xml A mqpar.xml file has to be provided for each pipeline. It has to be created using the MaxQuant GUI. Only a single .RAW file should be included. 4. Create MaxQuant Setup The MaxQuant Setup defines a pipeline. It is a combination of a MaxQuant binary, a MaxQuant parameter file (mqpar.xml) and a Fasta file. Once created you will be able to submit .RAW files to this pipeline. 5. Setup RawFile type for RawTools","title":"User Manual"},{"location":"manual/#user-manual","text":"Please, have a look at the installation instructions and how to start the pipeline server.","title":"User manual"},{"location":"manual/#login-with-an-admin-account","text":"When you visit the website for the first time you will be redirected to the login page. A new user can register a new account with a valid email address. To visit the admin page the user has to be granted the rights by an admin. If you do not have setup an admin account To setup a","title":"Login with an admin account"},{"location":"manual/#setup-maxquant","text":"To setup MaxQuant you can upload a zipped MaxQuant version. Version 1.6.14 works with Mono and is the recommended version to use with the Proteomics Pipelines server. Please contact the MaxQuant mailing list for information on how to obtain older versions. Once you downloaded the zip-file you can upload it to the Pipeline server. Go to 'admin/pipelines/maxquantbin/add' and upload the zip file from Admin / Max quant bins / ADD MAX QUANT BIN . If successful the executable will be selectable under Admin / Max quant setups / ADD MAX QUANT SETUP/ . If this is done you can create your first pipeline.","title":"Setup MaxQuant"},{"location":"manual/#create-first-pipeline","text":"","title":"Create first pipeline"},{"location":"manual/#1-create-a-new-project","text":"At least one project has to be set up. Navigate to Admin / Projects / ADD PROJECT and provide a name and a description.","title":"1. Create a new project"},{"location":"manual/#2-upload-fasta-file","text":"A fasta file with protein sequences has to be uploaded.","title":"2. Upload Fasta File"},{"location":"manual/#3-upload-mqparxml","text":"A mqpar.xml file has to be provided for each pipeline. It has to be created using the MaxQuant GUI. Only a single .RAW file should be included.","title":"3. Upload mqpar.xml"},{"location":"manual/#4-create-maxquant-setup","text":"The MaxQuant Setup defines a pipeline. It is a combination of a MaxQuant binary, a MaxQuant parameter file (mqpar.xml) and a Fasta file. Once created you will be able to submit .RAW files to this pipeline.","title":"4. Create MaxQuant Setup"},{"location":"manual/#5-setup-rawfile-type-for-rawtools","text":"","title":"5. Setup RawFile type for RawTools"}]}